# RSVG: Exploring Data and Model for Visual Grounding on Remote Sensing Data
##### Author: Zhan Yang 
This is the offical PyTorch code for paper **"RSVG: Exploring Data and Model for Visual Grounding on Remote Sensing Data"**, [Paper](https://ieeexplore.ieee.org/document/10056343).

## Please share a <font color='orange'>STAR â­</font> if this project does help


## ğŸ’¬ News
**[2023/04/09]**: Update the DIOR_RSVG dataset. (to clarify, we have been planning to continuously optimize this dataset, and the last public version was wrong and has now been restored.)
**[2022/11/07]**: Release the DIOR_RSVG dataset.  
**[2022/10/22]**: Release the training code. Publish the manuscript on arXiv.


## Introduction
This is Multi-Granularity Visual Language Fusion (MGVLF) Network, the PyTorch source code of the paper "RSVG: Exploring Data and Model for Visual Grounding on Remote Sensing Data". It is built on top of the [TransVG](https://github.com/djiajunustc/TransVG) in PyTorch. Our method is a transformer-based method for visual grounding for remote sensing data (RSVG). It has achieved the SOTA performance in the RSVG task on our constructed RSVG dataset.


### DIOR-RSVG Dataset
<p align="middle">
    <img src="fig/DIOR-RSVG.jpg">
</p>


### Network Architecture
<p align="middle">
    <img src="fig/MGVLF.jpg">
</p>



## Requirements and Installation
We recommended the following dependencies.
- Python 3.6.13
- PyTorch 1.9.0
- NumPy 1.19.2
- cuda 11.1
- opencv 4.5.5
- torchvision

## Download Data
Download our constructed RSVG dataset files. We build the first large-scale dataset for RSVG, termed DIOR-RSVG, which can be downloaded from our [Google Drive](https://drive.google.com/drive/folders/1hTqtYsC6B-m4ED2ewx5oKuYZV13EoJp_?usp=sharing). The download link is available below:
```
https://drive.google.com/drive/folders/1hTqtYsC6B-m4ED2ewx5oKuYZV13EoJp_?usp=sharing
```
   
We expect the directory and file structure to be the following:
```
./                      # current (project) directory
â”œâ”€â”€ models/             # Files for implementation of RSVG model
â”œâ”€â”€ utils/              # Some scripts for data processing and helper functions 
â”œâ”€â”€ saved_models/       # Savepath of pth/ckpt and pre-trained model
â”œâ”€â”€ logs/               # Savepath of logs
â”œâ”€â”€ data_loader.py      # Load data
â”œâ”€â”€ main.py             # Main code for training, validation, and test
â”œâ”€â”€ README.md
â””â”€â”€ RSVGD/              # DIOR-RSVG dataset
    â”œâ”€â”€ Annotations/    # Query expressions and bounding boxes
    â”‚   â”œâ”€â”€ 00001.xml/
    â”‚   â””â”€â”€ ..some xml files..
    â”œâ”€â”€ JPEGImages/     # Remote sensing images
    â”‚   â”œâ”€â”€ 00001.jpg/
    â”‚   â””â”€â”€ ..some jpg files..
    â”œâ”€â”€ train.txt       # ID of training set
    â”œâ”€â”€ val.txt         # ID of validation set
    â””â”€â”€ test.txt        # ID of test set
```

## Training and Evaluation
```
python main.py
```

Run ```main.py``` using ```--test False``` to train new models on DIOR-RSVG.
Evaluate trained models on DIOR-RSVG using ```--test True```.

## Reference
If you found this code useful, please cite the paper. Welcome :+1:_<big>`Fork and Star`</big>_:+1:, then I will let you know when we update.
```
@ARTICLE{10056343,
  author={Zhan, Yang and Xiong, Zhitong and Yuan, Yuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={RSVG: Exploring Data and Models for Visual Grounding on Remote Sensing Data}, 
  year={2023},
  volume={61},
  number={},
  pages={1-13},
  doi={10.1109/TGRS.2023.3250471}
  }
```

## Acknowledgments
Our DIOR-RSVG is constructed based on the [DIOR](http://www.escience.cn/people/JunweiHan/DIOR.html) remote sensing image dataset. We thank to the authors for releasing the dataset. Part of our code is borrowed from [TransVG](https://github.com/djiajunustc/TransVG). We thank to the authors for releasing codes. I would like to thank Xiong zhitong and Yuan yuan for helping the manuscript. I also thank the School of Artificial Intelligence, OPtics, and ElectroNics (iOPEN), Northwestern Polytechnical University for supporting this work.
